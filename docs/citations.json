{
  "references": {
    "nocedal-wright-2006": {
      "title": "Numerical Optimization",
      "authors": ["Jorge Nocedal", "Stephen J. Wright"],
      "year": 2006,
      "edition": "2nd",
      "publisher": "Springer",
      "file": "NumericalOptimization2006.pdf"
    },
    "boyd-vandenberghe-2004": {
      "title": "Convex Optimization",
      "authors": ["Stephen Boyd", "Lieven Vandenberghe"],
      "year": 2004,
      "publisher": "Cambridge University Press",
      "file": "Boyd+Vandenberghe-2004-Convex_optimization.pdf"
    },
    "nesterov-2004": {
      "title": "Introductory Lectures on Convex Optimization: A Basic Course",
      "authors": ["Yurii Nesterov"],
      "year": 2004,
      "publisher": "Kluwer Academic Publishers",
      "file": "Introductory-Lectures-on-Convex-Programming-Yurii-Nesterov-2004.pdf"
    },
    "liu-nocedal-1989": {
      "title": "On the Limited Memory BFGS Method for Large Scale Optimization",
      "authors": ["Dong C. Liu", "Jorge Nocedal"],
      "year": 1989,
      "journal": "Mathematical Programming",
      "volume": "45",
      "pages": "503-528",
      "file": "LiuNocedal1989.pdf"
    },
    "nesterov-2018": {
      "title": "Lectures on Convex Optimization",
      "authors": ["Yurii Nesterov"],
      "year": 2018,
      "edition": "2nd",
      "publisher": "Springer",
      "file": "Lectures on Convex Optimization.pdf"
    }
  },
  "citations": {
    "gd-strongly-convex-linear-convergence-nesterov-2018": {
      "reference": "nesterov-2018",
      "pages": "101-102",
      "theorem": "Theorem 2.1.15",
      "claim": "Gradient descent with fixed step size achieves linear convergence to the global minimum on strongly convex smooth functions when $0 < \\alpha \\leq 2/(L+\\mu)$",
      "quote": "If $f \\in \\mathscr{S}_{\\mu,L}^{1,1}(\\mathbb{R}^n)$ and $0 < h \\leq \\frac{2}{\\mu+L}$, then the Gradient Method generates a sequence $\\{x_k\\}$ such that $\\|x_k - x^*\\|^2 \\leq \\left(1 - \\frac{2h\\mu L}{\\mu+L}\\right)^k \\|x_0 - x^*\\|^2$",
      "notes": "Internal: This is the updated 2nd edition (2018) version of the same result from the 2004 edition. The theorem is essentially the same but with slightly refined notation using $\\mathscr{S}_{\\mu,L}^{1,1}$ instead of $S_{\\mu,L}^{1,1}$. The step size bound is $h \\leq 2/(\\mu+L)$ (allowing equality) instead of $h < 2/(L+\\mu)$. Can be used for comparison with the 2004 edition to determine which source to recommend.",
      "readerNotes": "The notation $\\mathscr{S}_{\\mu,L}^{1,1}(\\mathbb{R}^n)$ denotes strongly convex functions with strong convexity parameter $\\mu > 0$ and Lipschitz continuous gradient with constant $L$ (see Definition 2.1.3 on page 94). The condition number $Q = L/\\mu$ determines the convergence rate. With optimal step size $h = 2/(L+\\mu)$, the convergence rate is $\\left(\\frac{L-\\mu}{L+\\mu}\\right)^{2k} = \\left(\\frac{Q-1}{Q+1}\\right)^{2k}$, which provides exponentially fast (linear) convergence. Note: Nesterov uses $h$ for step size in the theorem statement; here we use $\\alpha$. This result differs from the merely convex case (Theorem 2.1.14), which has step size bound $2/L$ instead of $2/(L+\\mu)$.",
      "proofPages": [
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0093.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0094.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0101.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0102.png"
      ],
      "verified": "2025-11-11",
      "verifiedBy": "claude-code-agent",
      "verificationNotes": "Verified Theorem 2.1.15 (pages 101-102) and Definition 2.1.3 (page 94) for strongly convex functions. The quote is word-for-word accurate from the PDF. The theorem appears on page 101 (starting at the bottom) and continues to page 102. The step size condition allows equality ($h \\leq 2/(\\mu+L)$) unlike the 2004 edition which used strict inequality. Pages 93-94 provide the definition and characterization of strongly convex functions including Theorem 2.1.9 which gives equivalent conditions.",
      "usedIn": ["GdFixedTab"]
    },
    "nesterov-accelerated-optimal-rate-nesterov-2018": {
      "reference": "nesterov-2018",
      "pages": "102-114",
      "theorem": "Theorem 2.2.2 and Constant Step Scheme III (2.2.22)",
      "claim": "Nesterov's accelerated gradient method achieves the optimal convergence rate $O(1/k^2)$ for smooth convex functions, which is provably optimal among all first-order methods",
      "quote": "Let us take in (2.2.7) $\\gamma_0 = 3L + \\mu$. Then this scheme generates a sequence $\\{x_k\\}_{k=0}^{\\infty}$ such that $f(x_k) - f^* \\leq \\frac{2(4+q_f)L\\|x_0-x^*\\|^2}{3(k+1)^2}$. This means that method (2.2.7) is optimal for solving the unconstrained minimization problem (2.2.1) with $f \\in \\mathscr{S}_{\\mu,L}^{1,1}(\\mathbb{R}^n)$ and $\\mu \\geq 0$. If $\\mu = 0$, then this method is optimal.",
      "notes": "Internal: Used in GdFixedTab to explain Nesterov acceleration. This is the 2018 edition version with refined calligraphic notation. The general scheme (2.2.7) is developed in pages 102-111, with the constant step variant (Scheme III, equation 2.2.22) on page 114. Optimality is proven in Theorem 2.2.2 by comparing with Theorem 2.1.7 lower bound (pages 91-92). For μ=0 (smooth convex), equation (2.2.18) on page 112 gives the explicit rate: $f(x_k) - f^* \\leq \\frac{8L\\|x_0-x^*\\|^2}{3(k+1)^2}$, which is O(1/k²) compared to gradient descent's O(1/k) rate.",
      "readerNotes": "The notation $\\mathscr{S}_{\\mu,L}^{1,1}(\\mathbb{R}^n)$ denotes functions with strong convexity parameter $\\mu \\geq 0$ and Lipschitz continuous gradient with constant $L$. When $\\mu = 0$, this reduces to $\\mathscr{F}_L^{1,1}(\\mathbb{R}^n)$, the class of smooth convex functions. The $O(1/k^2)$ convergence rate is provably optimal: Theorem 2.1.7 (pages 91-92) establishes a lower bound showing that no first-order method can achieve better than $O(1/k^2)$ convergence for this function class. Nesterov's accelerated method matches this lower bound up to constant factors, proving optimality. Constant Step Scheme III (page 114, equation 2.2.22) shows the classic momentum form: $x_{k+1} = y_k - \\frac{1}{L}\\nabla f(y_k)$, $y_{k+1} = x_{k+1} + \\frac{1-\\sqrt{q_f}}{1+\\sqrt{q_f}}(x_{k+1} - x_k)$ where $q_f = \\mu/L$. For smooth convex functions ($\\mu=0$), the method requires a different parameter choice to avoid division by zero, as shown in Constant Step Scheme II (page 113).",
      "proofPages": [
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0091.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0092.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0102.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0103.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0104.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0105.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0106.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0107.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0108.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0109.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0110.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0111.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0112.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0113.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0114.png"
      ],
      "verified": "2025-11-11",
      "verifiedBy": "claude-code-agent",
      "verificationNotes": "Verified Theorem 2.2.2 (pages 110-111, optimality claim), Constant Step Scheme III (2.2.22) on page 114 which is the classic Nesterov acceleration with momentum, and Theorem 2.1.7 (pages 91-92, lower complexity bound). The quote is from page 110 (Theorem 2.2.2). Visual verification confirmed the O(1/k²) rate for μ=0 (equation 2.2.18 on page 112) and the optimality proof which shows the method matches the information-theoretic lower bound. Pages 102-109 develop the estimating sequence framework (Definition 2.2.1, Lemmas 2.2.1-2.2.4) and general optimal method scheme (2.2.7). Pages 110-111 prove optimality. Pages 112-114 derive the simplified constant step schemes with explicit momentum coefficients.",
      "usedIn": ["GdFixedTab"]
    },
    "gd-convex-sublinear-convergence-nesterov-2018": {
      "reference": "nesterov-2018",
      "pages": "81",
      "theorem": "Theorem 2.1.14 and Corollary 2.1.2",
      "claim": "Gradient descent with fixed step size converges to the global minimum on convex smooth functions (possibly slowly with sublinear rate) when $0 < \\alpha \\leq 2/L$",
      "quote": "Let $f \\in \\mathscr{F}_L^{1,1}(\\mathbb{R}^n)$ and $0 < h \\leq 2/L$. Then the Gradient Method generates a sequence $\\{x_k\\}$ such that $\\|x_k - x^*\\|^2 \\leq q^k \\|x_0 - x^*\\|^2$, where $q = 1 - \\frac{h}{2}(2-hL) \\in [0,1)$. [Corollary 2.1.2] If $h = 1/L$ and $f \\in \\mathscr{F}_L^{1,1}(\\mathbb{R}^n)$, then $f(x_k) - f^* \\leq \\frac{L\\|x_0-x^*\\|^2}{2(k+1)}$",
      "notes": "Internal: Used in GdFixedTab to explain convex (non-strongly) convergence. This is the 2018 edition update of the 2004 result, using calligraphic notation $\\mathscr{F}_L^{1,1}$ instead of $F_L^{1,1}$. The step size bound allows equality ($h \\leq 2/L$) instead of strict inequality ($h < 2/L$) in the 2004 edition. This is the $\\mu=0$ case compared to Theorem 2.1.15.",
      "readerNotes": "The notation $\\mathscr{F}_L^{1,1}(\\mathbb{R}^n)$ denotes convex functions with Lipschitz continuous gradient with constant $L$ (see Definition 2.1.2 on page 62). With optimal step size $\\alpha = 1/L$, the convergence rate is $O(1/k)$, which is sublinear convergence. Note: Nesterov uses $h$ for step size in the theorem statement; here we use $\\alpha$. This is much slower than the exponentially fast convergence for strongly convex functions (Theorem 2.1.15, with step size bound $2/(L+\\mu)$) - without strong convexity, gradient descent loses the geometric convergence rate and can only guarantee polynomial convergence.",
      "proofPages": [
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0059.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0062.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0080.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0081.png"
      ],
      "verified": "2025-11-11",
      "verifiedBy": "claude-code-agent",
      "verificationNotes": "Verified Theorem 2.1.14 and Corollary 2.1.2 on page 81. The quote is extracted from visual verification of the PDF pages. The theorem provides convergence in terms of distance to optimum, while Corollary 2.1.2 provides the $O(1/k)$ sublinear rate in function values with optimal step size $h=1/L$. Page 62 provides Definition 2.1.2 for convex functions. Page 59 contains the beginning of Section 2.1.1 (Smooth Convex Functions) where the function class $\\mathscr{F}_L^{1,1}$ is introduced. Page 80 contains the beginning of Section 2.1.5 (The Gradient Method). The step size bound allows equality ($h \\leq 2/L$) which is a refinement from the 2004 edition's strict inequality.",
      "usedIn": ["GdFixedTab"]
    },
    "gd-smooth-descent-condition-nesterov-2018": {
      "reference": "nesterov-2018",
      "pages": "81",
      "theorem": "Theorem 2.1.14",
      "claim": "With step size $\\alpha \\leq 2/L$, gradient descent guarantees that $f(w_{k+1}) < f(w_k)$ for smooth functions (Lipschitz continuous gradient with constant $L$).",
      "quote": "Let $f \\in \\mathscr{F}_L^{1,1}(\\mathbb{R}^n)$ and $0 < h \\leq 2/L$. Then the Gradient Method generates a sequence $\\{x_k\\}$, which converges to some optimal point $x^*$.",
      "notes": "Internal: Used in GdFixedTab to explain the sufficient condition for descent on smooth functions. This is the 2018 edition version using calligraphic notation $\\mathscr{F}_L^{1,1}$ instead of $F_L^{1,1}$ from the 2004 edition. The step size bound allows equality ($h \\leq 2/L$) instead of strict inequality ($h < 2/L$). The descent property follows from the fundamental inequality for smooth functions (see Lemma 1.2.3 on page 23 which shows $f(y) \\leq f(x) + \\langle \\nabla f(x), y-x \\rangle + \\frac{L}{2}\\|y-x\\|^2$ for L-smooth functions), which combined with the gradient step yields descent when $h \\leq 2/L$.",
      "readerNotes": "The notation $\\mathscr{F}_L^{1,1}(\\mathbb{R}^n)$ denotes convex functions with Lipschitz continuous gradient with constant $L$ (the function class is defined in Section 2.1.1, pages 59-69; see Definition 2.1.2 on page 62 for convex functions). However, the descent property itself follows from the upper bound inequality for smooth functions (Lemma 1.2.3 on page 23), which holds for any function with Lipschitz continuous gradient, not just convex functions. The condition $\\alpha \\leq 2/L$ ensures that each gradient descent step decreases the function value. Note: Nesterov uses $h$ for step size; here we use $\\alpha$. This is a more general result than convergence - it guarantees monotonic decrease at each step. The 2018 edition uses calligraphic script $\\mathscr{F}$ for function classes instead of the regular $F$ used in the 2004 edition, and allows equality in the step size bound ($h \\leq 2/L$) instead of strict inequality ($h < 2/L$).",
      "proofPages": [
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0059.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0060.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0062.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0080.png",
        "docs/references/extracted-pages/lectures_on_convex_optimization_page_0081.png"
      ],
      "verified": "2025-11-11",
      "verifiedBy": "claude-code-agent",
      "verificationNotes": "Verified Theorem 2.1.14 on page 81 which states the gradient method convergence for smooth convex functions with step size bound $0 < h \\leq 2/L$. The theorem explicitly states convergence, and the descent property is implied by the proof which uses the fundamental inequality for L-smooth functions (Lemma 1.2.3 on page 23). Pages 59-60 provide context on Chapter 2 (Smooth Convex Optimization) structure. Page 62 contains Definition 2.1.2 for convex functions. Pages 80-81 contain Section 2.1.5 'The Gradient Method' where Theorem 2.1.14 appears. The step size condition $h \\leq 2/L$ (allowing equality) is explicitly stated in the theorem, which is a refinement from the 2004 edition's strict inequality $h < 2/L$.",
      "usedIn": ["GdFixedTab"]
    }
  }
}
